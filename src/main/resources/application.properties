spring.application.name=ollama
# 默认编码
server.servlet.encoding.charset=UTF-8
server.servlet.encoding.enabled=true
server.servlet.encoding.force=true


server.port=30000

logging.level.org.self4m.ollama_java=DEBUG
logging.file.name=ollama.log

# ollama 配置
# ollama 链接
spring.ai.ollama.base-url=http://127.0.0.1:16969
# ollama 模型名称
spring.ai.ollama.model=deepseek-r1:1.5b
# ollama 对话参数配置
spring.ai.ollama.chat.options.temperature=0.8
spring.ai.ollama.chat.options.max-tokens=8192
spring.ai.ollama.chat.options.top-p=0.9
spring.ai.ollama.chat.options.top-k=40